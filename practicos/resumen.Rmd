---
title: "Resumen para el segundo parcial"
geometry: margin=1.5cm
output: pdf_document
header-includes:
  \usepackage{fvextra}
  \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.dim = c(6, 3.5), fig.align='center', message=FALSE, warning=FALSE)
library(knitr)
library(KScorrect)
library(tidyr)
```

# Hipótesis nulas y p-valores para los tests
## Kolmogorov-Smirnov
Este test pone a prueba si una función desconocida ($F_{X}$) tiene la misma distribución que la conocida ($F_{0}$). Entonces si el $p-valor>\alpha$ diríamos que no hay evidencia suficiente para rechazar $H_{0}$.
$$\left\{\begin{matrix}
H_{0}: F_{x}=F_{0}\\ 
H_{1}: F_{x}\neq F_{0}
\end{matrix}\right.$$

```{r echo=FALSE}
datos <- c(5.3,5.1,4.8,4.9,5.3,5.2,5.8,5.5,5.6,5.2)
x <- seq(4.7, 5.9, 0.12)
par(mar=c(2,2,2,2))
```

**_Ejemplo:_ Ejercicio 1 del práctico 9.**

Donde la distribución conocida es $Unif(4.7, 5.9)$. Y los datos son: [`r datos`]. La prueba de hipótesis va a ser de la siguiente forma:

$$\left\{\begin{matrix}
H_{0}: F_{x}=Unif(4.7, 5.9)\\ 
H_{1}: F_{x}\neq Unif(4.7, 5.9)
\end{matrix}\right.$$

Primero planteo Kolmogorov-Smirnov:
$$K_{n}=D \times \sqrt{n} \rightarrow  \mathcal{K}$$
La región crítica va a tener la siguiente forma:
$$RC=\left \{ \sqrt{n} \times D > t_{1-\alpha} \right \}$$ 
Para $n>30$ utilizamos:
$$t_{1-\alpha}\approx \sqrt{-\frac{1}{2}Ln(\frac{\alpha}{2})}$$
Sino hay que usar la tabla y buscar el valor $t_{1-\alpha}$ para un $n$ y un $\alpha$.

Ahora continuamos hallando el valor de _D_.
$$D=sup\left | F_{X}(x)-F_{0}(x) \right |$$
$F_{X}(x)$ es el valor de la distribución desconocida que más se aleja de $F_{0}$. En este caso es el quinto valor (en orden ascendente) y es aproximadamente ~0.7 (linea roja). Y el $F_{0}(x)$ sería el valor al que le corresponde el anterior si fuese de la distribución conocida, en este caso, podemos ver donde se cruzan las rectas azules y es igual a _~0.5_.
Entonces, ahora hago todas las cuentas con los números:
$$D=sup\left | 0.7-0.5 \right | = 0.2$$
Utilizo la tabla para buscar el valor de $t_{1-\alpha}$ para $n=10$ y $\alpha = 0.05$ (recordar que es bilateral) y obtengo:
$$t_{1-\alpha}=0.40925$$

Finalmente:

$$RC=\left \{ D \times \sqrt{n} > 0.40925 \right \}$$

Ya que $D \times \sqrt{n}=0.63$ es más grande que $t_{1-\alpha}$ se puede decir que rechazamos $H_{0}$.

```{r echo=FALSE}
par(mar = c(2,2,2,2))
plot(x, punif(x, min = 4.7, max = 5.9), type = "l", ylim = c(0,1))
lines(ecdf(datos))
abline(h=c(0.5, 0.7), v=datos[5], lty=2, col=c("blue", "red", "blue"))
```

``` {r}
test_ks <- ks.test(datos,"punif", 4.7, 5.9)
test_ks
```

Al realizar el ejercicio en R obtenemos un p-valor de `r round(test_ks$p.value, 3)`, ya que es mayor a _0.05_ podemos decir que no hay evidencias significativas como para rechazar $H_{0}$. Y esto es completamente lo contrario a lo que nos da al calcular _"a mano"_, donde rechazabamos $H_{0}$

## Kolmogorov-Smirnov 2 muestras:
Esta prueba testea si dos distribuciones son iguales. La prueba de hipótesis va a ser de la siguiente forma:

$$\left\{\begin{matrix}
H_{0}: F_{X}=F_{Y}\\ 
H_{1}: F_{X}\neq F_{Y}
\end{matrix}\right.$$

El estadístico va a ser:

$$K_{m,n}:= \sqrt{\frac{nm}{n+m}}  \text{sup} \left | F_{n}(x) - F_{m}(x) \right | \overset{d}{\rightarrow} \mathcal{K}$$

La región crítica será:


$$RC = \left \{ D_{n,m}> t_{n,m} \right \}$$

Ahora hay que hallar un $t_{1-\alpha}$ tal que $P(\mathcal{K}>t_{1-\alpha})=\alpha$. Y este valor se obtiene desde una tabla o usando la fórmula aproximada si $n>40$ igual que en la parte de K-S de una muestra.

Rechazaremos $H_{0}$ si:

$$\sqrt{\frac{nm}{n+m}}D_{n,m} > t_{1-\alpha}$$

El _D_ se obtiene de igual forma que el test para una mustra.

Ejemplo:

```{r}
x=runif(200)
y=runif(250)
ks.test(x, y)
# Gráfica
par(mar = c(2,2,2,2))
plot(ecdf(x))
plot(ecdf(y), add=TRUE, col="blue")
```

Si el $p-valor>\alpha$ entonces diríamos que no hay evidencia suficiente para rechazar $H_{0}$.

## Lilliefors

\begin{center} \textbf{No realizamos este test "\emph{a mano}", solo se hizo en R} \end{center}

Pone a prueba lo mismo que Kolmogorov-Smirnov, pero se utiliza cuando no se conoce la media, ni la varianza, ni ningún parámetro que necesite la distribución. $H_{0}$ será de la forma:

$$\left\{\begin{matrix}
H_{0}:\in \left \{ N(\mu , \sigma): \sigma > 0, \mu>0 \right \}
\\ 
H_{1}: \text{"no pertenece a la familia"}
\end{matrix}\right.$$

Donde todo lo que esta entre {} es el conjunto de todas las variables  (en este caso) con alguna media $\mu$ y algún desvío $\sigma$.

**Ejercicio 3 del práctico 9**

```{r}
# No son los mismos que se ven en el práctico porque estos ya estan estandarizados.
datosLilliefors <- c(-0.085 , -2.46 , -0.335 , 0.235 , 0.645 , -0.075 , 0.965 , -1.38 , -2.115 , -0.055 , -0.48 , 0.615 , 1.315 , 0.11 , -0.445 , 0.61)
# Realizo el test
testLilliefors <- LcKS(datosLilliefors,"pnorm")
```

Este test devuelve los siguientes datos:

  1. Un "D observado" `r testLilliefors$D.obs`.
  2. Un vector muy grande que se llama "D.sim", no se qué significa.
  3. El p-valor: `r testLilliefors$p.value`.

Como el $p-valor > \alpha$ no hay evidencias suficientes para rechazar $H_{0}$ a nivel _5%_, es decir que la muestra proviene de una $\mathcal{N}(\mu, \sigma)$

## Prueba de $\mathcal{X}^{2}$ de Pearson

Este test sirve únicamente para **distribuciones discretas**, no continuas como los anteriores.

## Prueba de Spearman de una muestra

Testea si una muestra tiene un comportamiento monóntono, si es creciente o no, si es _i.i.d_ no tiene un comportamiento monótono.

La pruba de hipótesis sera: 

$$\left\{\begin{matrix}
H_{0}: X_{1},...,X_{n} \text{ son i.i.d} \\ 
H_{1}: X_{1},...,X_{n} \text{ no son i.i.d} 
\end{matrix}\right.$$

Y el estadístico tiene la siguiente forma:

$$\rho_{s}=1 - \frac{6S}{n(n^{2}-1)}$$

Con

$$S = \sum_{i=1}^{n}(R_{i}-i)^{2}$$

\newpage

**Ejercicio 1 del práctico 10**

```{r echo=FALSE, results='asis'}
datoS1 <- c(74.3, 74.1, 75.4, 67.4, 69.3, 70.5, 70.1, 69.9, 68.7, 70.3, 70.7, 71.1, 74.4, 70.2)

tabla <- data.frame(i = 1:length(datoS1), valores=datoS1, Ri = rank(datoS1))
kable(tabla)

```

Entonces calculamos $S$ y nos queda:

$$S=(12-1)^{2}+(11-2)^{2}+(14-3)^{2}+...+(6-14)^{2}=$$

## Prueba de Spearman de dos muestras




